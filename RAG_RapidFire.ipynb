{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc8dMxjZ3xCO"
      },
      "source": [
        "Install & setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY6TrfRa31-E"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B2Pho4r36Zd"
      },
      "source": [
        "Load & prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofbaO0MQ3_FJ"
      },
      "source": [
        "Build corpus + queries + qrels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENGjn4Bu4CQC"
      },
      "source": [
        "Write corpus to disk (RapidFire expects files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR3lvLZR4KRf"
      },
      "source": [
        "Queries DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDvR6QKY4Otx"
      },
      "source": [
        "Define RAG search space (retrieval-focused)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIW4yc7h4R0z"
      },
      "source": [
        "Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmtoJWa_4ZeA"
      },
      "source": [
        "Preprocess (retrieval-only focus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m0b2Zfv4d5V"
      },
      "source": [
        "Postprocess (attach ground truth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U0dxiB64jVP"
      },
      "source": [
        "Metrics (Precision / Recall / MRR / NDCG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yir3wRg44zYn"
      },
      "source": [
        "Grid + Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvbAUY8k46xD"
      },
      "source": [
        "Run hyperparallel evals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzmJKUwR4_H8"
      },
      "source": [
        "Results table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzKuMbtRVmR7",
        "outputId": "1d8c3c7d-ffc0-4a4a-870b-b7eb9a830486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "home: 17679 reviews\n",
            "apparel: 15951 reviews\n",
            "wireless: 15717 reviews\n",
            "other: 13418 reviews\n",
            "beauty: 12091 reviews\n",
            "drugstore: 11730 reviews\n",
            "kitchen: 10382 reviews\n",
            "toy: 8745 reviews\n",
            "sports: 8277 reviews\n",
            "automotive: 7506 reviews\n",
            "lawn_and_garden: 7327 reviews\n",
            "home_improvement: 7136 reviews\n",
            "pet_products: 7082 reviews\n",
            "digital_ebook_purchase: 6749 reviews\n",
            "pc: 6401 reviews\n",
            "electronics: 6186 reviews\n",
            "office_product: 5521 reviews\n",
            "shoes: 5197 reviews\n",
            "grocery: 4730 reviews\n",
            "book: 3756 reviews\n",
            "baby_product: 3150 reviews\n",
            "furniture: 2984 reviews\n",
            "jewelry: 2747 reviews\n",
            "camera: 2139 reviews\n",
            "industrial_supplies: 1994 reviews\n",
            "digital_video_download: 1364 reviews\n",
            "luggage: 1328 reviews\n",
            "musical_instruments: 1102 reviews\n",
            "video_games: 775 reviews\n",
            "watch: 761 reviews\n",
            "personal_care_appliances: 75 reviews\n"
          ]
        }
      ],
      "source": [
        "# from collections import Counter\n",
        "\n",
        "# # This will give you a dictionary of {category: count}\n",
        "# category_counts = Counter(raw_dataset[\"product_category\"])\n",
        "\n",
        "# # Print them nicely sorted by the most popular\n",
        "# for category, count in category_counts.most_common():\n",
        "#     print(f\"{category}: {count} reviews\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-3zxViiaKOmG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "msQywY7UigG2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa0al-5PkKa_"
      },
      "source": [
        "gem new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeOJRDEll5pR",
        "outputId": "476d806f-cba5-4c87-e877-6242c1362060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfireai\n",
            "  Downloading rapidfireai-0.12.9-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting datasets==3.6.0\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==3.6.0) (6.0.3)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from rapidfireai) (3.1.2)\n",
            "Collecting flask-cors (from rapidfireai)\n",
            "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting waitress (from rapidfireai)\n",
            "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jq (from rapidfireai)\n",
            "  Downloading jq-1.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting jedi (from rapidfireai)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting uv (from rapidfireai)\n",
            "  Downloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting trackio (from rapidfireai)\n",
            "  Downloading trackio-0.15.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting mlflow (from rapidfireai)\n",
            "  Downloading mlflow-3.8.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==3.6.0) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==3.6.0) (2026.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask->rapidfireai) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask->rapidfireai) (8.3.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask->rapidfireai) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask->rapidfireai) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask->rapidfireai) (3.1.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi->rapidfireai) (0.8.5)\n",
            "Collecting mlflow-skinny==3.8.1 (from mlflow->rapidfireai)\n",
            "  Downloading mlflow_skinny-3.8.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.8.1 (from mlflow->rapidfireai)\n",
            "  Downloading mlflow_tracing-3.8.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow->rapidfireai) (1.18.1)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow->rapidfireai) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow->rapidfireai)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow->rapidfireai)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow->rapidfireai)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow->rapidfireai)\n",
            "  Downloading huey-2.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow->rapidfireai) (3.10.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow->rapidfireai) (2.0.45)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (6.2.4)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.8.1->mlflow->rapidfireai)\n",
            "  Downloading databricks_sdk-0.80.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.123.10)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (3.1.46)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (8.7.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (5.29.5)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (1.2.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.5.5)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.40.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.6.0) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Collecting gradio<7.0.0,>=6.3.0 (from gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai)\n",
            "  Downloading gradio-6.4.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from trackio->rapidfireai) (3.11.5)\n",
            "Requirement already satisfied: pillow<12.0.0 in /usr/local/lib/python3.12/dist-packages (from trackio->rapidfireai) (11.3.0)\n",
            "Collecting plotly<7.0.0,>=6.0.0 (from trackio->rapidfireai)\n",
            "  Downloading plotly-6.5.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pydub<1.0.0 in /usr/local/lib/python3.12/dist-packages (from trackio->rapidfireai) (0.25.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow->rapidfireai) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow->rapidfireai) (2.0.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (1.2.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (1.0.0)\n",
            "Collecting gradio-client==2.0.3 (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai)\n",
            "  Downloading gradio_client-2.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.0.21)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.21.1)\n",
            "Requirement already satisfied: authlib in /usr/local/lib/python3.12/dist-packages (from gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (1.6.6)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow->rapidfireai)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow->rapidfireai)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.25.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->rapidfireai) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->rapidfireai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->rapidfireai) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->rapidfireai) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow->rapidfireai) (3.3.1)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly<7.0.0,>=6.0.0->trackio->rapidfireai) (2.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->rapidfireai) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow->rapidfireai) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (2.43.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow->rapidfireai) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.58b0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (13.9.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow->rapidfireai) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (4.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<7.0.0,>=6.3.0->gradio[oauth]<7.0.0,>=6.3.0->trackio->rapidfireai) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow->rapidfireai) (0.6.2)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfireai-0.12.9-py3-none-any.whl (46.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jq-1.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (773 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m773.8/773.8 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow-3.8.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m145.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.8.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trackio-0.15.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uv-0.9.27-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.7/22.7 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-6.4.0-py3-none-any.whl (24.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.6.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.5.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m121.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.80.0-py3-none-any.whl (788 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m788.3/788.3 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, waitress, uv, plotly, jq, jedi, gunicorn, graphql-core, graphql-relay, docker, graphene, gradio-client, flask-cors, databricks-sdk, gradio, datasets, mlflow-tracing, mlflow-skinny, trackio, mlflow, rapidfireai\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed databricks-sdk-0.80.0 datasets-3.6.0 docker-7.1.0 flask-cors-6.0.2 gradio-6.4.0 gradio-client-2.0.3 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.6.0 jedi-0.19.2 jq-1.11.0 mlflow-3.8.1 mlflow-skinny-3.8.1 mlflow-tracing-3.8.1 plotly-6.5.2 rapidfireai-0.12.9 trackio-0.15.0 uv-0.9.27 waitress-3.0.2\n",
            "Created directory: /content/rapidfireai/logs\n",
            "ğŸ”§ Initializing RapidFire AI project...\n",
            "------------------------------\n",
            "Initializing project...\n",
            "Colab environment detected, installing evals packages\n",
            "Installing packages from /usr/local/lib/python3.12/dist-packages/setup/evals/requirements-colab.txt...\n",
            "âœ… Successfully installed packages from /usr/local/lib/python3.12/dist-packages/setup/evals/requirements-colab.txt\n",
            "Getting tutorial notebooks...\n",
            "Copying tutorial notebooks from /usr/local/lib/python3.12/dist-packages/tutorial_notebooks to ./tutorial_notebooks...\n",
            "âœ… Successfully copied notebooks to ./tutorial_notebooks\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import rapidfireai\n",
        "    print(\"âœ… rapidfireai installed\")\n",
        "except ImportError:\n",
        "    !pip install rapidfireai datasets==3.6.0 langchain sentence-transformers\n",
        "    !rapidfireai init --evals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uyPBQTeFkNEw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List as listtype, Dict, Any\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Critical for Colab compatibility\n",
        "os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n",
        "\n",
        "from rapidfireai import Experiment\n",
        "from rapidfireai.automl import List, RFLangChainRagSpec, RFvLLMModelConfig, RFPromptManager, RFGridSearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, row in enumerate(sampled_data):\n",
        "#     print(row)\n",
        "#     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Ympb9F9Oe-",
        "outputId": "bdd8b184-ec91-4380-84f5-0f80e167ac45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'review_id': 'en_0760000', 'product_id': 'product_en_0049787', 'reviewer_id': 'reviewer_en_0204668', 'stars': 1, 'review_body': 'One ear bud lasted only 2 weeks. The other went out 3 months later. Not worth the money or frustration', 'review_title': 'One ear bud lasted only 2 weeks. The other ...', 'language': 'en', 'product_category': 'electronics'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "\n",
        "# 1. Setup\n",
        "dataset_dir = Path(\"./electronics_rag\")\n",
        "dataset_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# 2. Load and Filter\n",
        "raw_dataset = load_dataset(\"buruzaemon/amazon_reviews_multi\", \"en\", split=\"train\")\n",
        "electronics_data = raw_dataset.filter(lambda x: \"electronics\" in x[\"product_category\"].lower())\n",
        "\n",
        "# 3. Downsample (Using a larger set to ensure product overlaps)\n",
        "sample_size = 100\n",
        "rseed = 42\n",
        "random.seed(rseed)\n",
        "sampled_data = electronics_data.shuffle(seed=rseed).select(range(sample_size))\n",
        "\n",
        "# 4. Grouping Logic\n",
        "# We need to know which documents belong to which product\n",
        "product_to_docs = defaultdict(list)\n",
        "corpus_list = []\n",
        "queries_list = []\n",
        "\n",
        "for i, row in enumerate(sampled_data):\n",
        "    doc_id = f\"doc_{i}\"\n",
        "    query_id = f\"q_{i}\"\n",
        "    prod_id = str(row['product_id'])\n",
        "\n",
        "    # Store the document\n",
        "    corpus_list.append({\"_id\": doc_id, \"text\": row[\"review_body\"]})\n",
        "\n",
        "    # Store the query (using title)\n",
        "    queries_list.append({\"query_id\": query_id, \"query\": row[\"review_title\"]})\n",
        "\n",
        "    # Map this document to its product group\n",
        "    product_to_docs[prod_id].append(doc_id)\n",
        "\n",
        "# 5. Build Expanded QRELS\n",
        "qrels_rows = []\n",
        "for i, row in enumerate(sampled_data):\n",
        "    query_id = f\"q_{i}\"\n",
        "    prod_id = str(row['product_id'])\n",
        "\n",
        "    # Every document sharing this product_id is now a \"correct\" answer\n",
        "    relevant_docs = product_to_docs[prod_id]\n",
        "\n",
        "    for d_id in relevant_docs:\n",
        "        qrels_rows.append({\n",
        "            \"query_id\": query_id,\n",
        "            \"corpus_id\": d_id,\n",
        "            \"relevance\": 1\n",
        "        })\n",
        "\n",
        "# 6. Save and Finalize\n",
        "corpus_file = dataset_dir / \"corpus_sampled.jsonl\"\n",
        "with open(corpus_file, \"w\") as f:\n",
        "    for doc in corpus_list:\n",
        "        f.write(json.dumps(doc) + \"\\n\")\n",
        "\n",
        "electronics_dataset = pd.DataFrame(queries_list).astype(str)\n",
        "qrels = pd.DataFrame(qrels_rows).astype(str)\n",
        "\n",
        "print(f\"âœ… Prepared {len(corpus_list)} documents.\")\n",
        "print(f\"âœ… Expanded QRELS: {len(qrels)} relevance pairs (Multiple reviews per product).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_4xxB7s_kl-",
        "outputId": "4ec9df89-0aae-4882-80b2-675ea2e7eff4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prepared 100 documents.\n",
            "âœ… Expanded QRELS: 100 relevance pairs (Multiple reviews per product).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader, JSONLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_classic.retrievers.document_compressors import CrossEncoderReranker\n",
        "\n",
        "# Batch size for embedding model hardware efficiency\n",
        "batch_size = 50\n",
        "\n",
        "rag_gpu = RFLangChainRagSpec(\n",
        "    document_loader=DirectoryLoader(\n",
        "        path=str(dataset_dir),\n",
        "        glob=\"corpus_sampled.jsonl\",\n",
        "        loader_cls=JSONLoader,\n",
        "        loader_kwargs={\n",
        "            \"jq_schema\": \".\",\n",
        "            \"content_key\": \"text\",\n",
        "            \"metadata_func\": lambda record, metadata: {\n",
        "                \"corpus_id\": str(record.get(\"_id\")) # CRITICAL: Must be string\n",
        "            },\n",
        "            \"json_lines\": True,\n",
        "            \"text_content\": False,\n",
        "        },\n",
        "        sample_seed=42,\n",
        "    ),\n",
        "    # testing 2 chunking granularities\n",
        "    text_splitter=List([\n",
        "            RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=32),\n",
        "            RecursiveCharacterTextSplitter(chunk_size=128, chunk_overlap=32),\n",
        "        ],\n",
        "    ),\n",
        "    embedding_cls=HuggingFaceEmbeddings,\n",
        "    embedding_kwargs={\n",
        "        \"model_name\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        \"model_kwargs\": {\"device\": \"cuda:0\"},\n",
        "        \"encode_kwargs\": {\"normalize_embeddings\": True, \"batch_size\": batch_size},\n",
        "    },\n",
        "    vector_store=None,  # Defaults to FAISS\n",
        "    search_type=\"similarity\",\n",
        "    # INCREASED K: Fetch more candidates because many reviews are now 'correct'\n",
        "    search_kwargs={\"k\": 20},\n",
        "\n",
        "    reranker_cls=CrossEncoderReranker,\n",
        "    reranker_kwargs={\n",
        "        \"model_name\": \"cross-encoder/ms-marco-MiniLM-L6-v2\",\n",
        "        \"model_kwargs\": {\"device\": \"cpu\"},\n",
        "        # INCREASED TOP_N: Allow more product-relevant evidence through to the LLM\n",
        "        \"top_n\": List([5, 10]),\n",
        "    },\n",
        "    enable_gpu_search=True, # Stability fix for Colab environment\n",
        ")"
      ],
      "metadata": {
        "id": "m8jldNPpALMk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_preprocess_fn(batch: Dict[str, listtype], rag: RFLangChainRagSpec, prompt_manager: RFPromptManager) -> Dict[str, listtype]:\n",
        "    INSTRUCTIONS = \"Utilize your knowledge of electronics to answer the following question based on the provided reviews.\"\n",
        "\n",
        "    # 1. Cast queries to strings to avoid 'AttributeError' in retrieval\n",
        "    batch_queries = [str(q).strip() for q in batch[\"query\"]]\n",
        "\n",
        "    # 2. Perform retrieval\n",
        "    all_context = rag.get_context(batch_queries=batch_queries, serialize=False)\n",
        "\n",
        "    # 3. Explicitly extract and cast IDs to strings to match QRELS\n",
        "    retrieved_documents = [\n",
        "        [str(doc.metadata.get(\"corpus_id\", \"\")).strip() for doc in docs]\n",
        "        for docs in all_context\n",
        "    ]\n",
        "\n",
        "    serialized_context = rag.serialize_documents(all_context)\n",
        "\n",
        "    return {\n",
        "        \"prompts\": [\n",
        "            [\n",
        "                {\"role\": \"system\", \"content\": INSTRUCTIONS},\n",
        "                {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {question}\"},\n",
        "            ]\n",
        "            for question, context in zip(batch_queries, serialized_context)\n",
        "        ],\n",
        "        \"retrieved_documents\": retrieved_documents,\n",
        "        # Ensure all original batch keys are passed through as lists\n",
        "        **{k: list(v) for k, v in batch.items()},\n",
        "    }\n",
        "\n",
        "def sample_postprocess_fn(batch: Dict[str, listtype]) -> Dict[str, listtype]:\n",
        "    # Ensure ID comparison is string-to-string to avoid empty lists\n",
        "    batch[\"ground_truth_documents\"] = [\n",
        "        qrels[qrels[\"query_id\"].astype(str) == str(qid).strip()][\"corpus_id\"].tolist()\n",
        "        for qid in batch[\"query_id\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "def compute_ndcg_at_k(retrieved_docs, expected_docs, k=5):\n",
        "    relevance = [1 if doc in expected_docs else 0 for doc in list(retrieved_docs)[:k]]\n",
        "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance))\n",
        "    ideal_length = min(k, len(expected_docs))\n",
        "    idcg = sum(1 / math.log2(i + 2) for i in range(ideal_length))\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def sample_compute_metrics_fn(batch: Dict[str, listtype]) -> Dict[str, Dict[str, Any]]:\n",
        "    precisions, recalls, ndcgs, rrs, hits = [], [], [], [], []\n",
        "    total_queries = len(batch[\"query\"])\n",
        "\n",
        "    for pred, gt in zip(batch[\"retrieved_documents\"], batch[\"ground_truth_documents\"]):\n",
        "        # Use sets for O(1) intersection performance\n",
        "        actual = set(str(p).strip() for p in pred)\n",
        "        expected = set(str(g).strip() for g in gt)\n",
        "\n",
        "        tp = len(actual.intersection(expected))\n",
        "\n",
        "        precisions.append(tp / len(actual) if actual else 0)\n",
        "        recalls.append(tp / len(expected) if expected else 0)\n",
        "        ndcgs.append(compute_ndcg_at_k(pred, expected, k=5))\n",
        "\n",
        "        # Hit Rate: Did we get at least one review for the right product?\n",
        "        hits.append(1 if tp > 0 else 0)\n",
        "\n",
        "        # Reciprocal Rank calculation\n",
        "        rr = 0\n",
        "        for i, p in enumerate(pred):\n",
        "            if str(p).strip() in expected:\n",
        "                rr = 1 / (i + 1)\n",
        "                break\n",
        "        rrs.append(rr)\n",
        "\n",
        "    return {\n",
        "        \"Total\": {\"value\": total_queries},\n",
        "        \"Hit Rate\": {\"value\": sum(hits) / total_queries}, # NEW\n",
        "        \"Precision\": {\"value\": sum(precisions) / total_queries},\n",
        "        \"Recall\": {\"value\": sum(recalls) / total_queries},\n",
        "        \"NDCG@5\": {\"value\": sum(ndcgs) / total_queries},\n",
        "        \"MRR\": {\"value\": sum(rrs) / total_queries},\n",
        "    }\n",
        "\n",
        "def sample_accumulate_metrics_fn(aggregated_metrics: Dict[str, listtype]) -> Dict[str, Dict[str, Any]]:\n",
        "    total_queries = sum(m[\"value\"] for m in aggregated_metrics[\"Total\"])\n",
        "    # Added Hit Rate to the algebraic accumulation list\n",
        "    metrics = [\"Hit Rate\", \"Precision\", \"Recall\", \"NDCG@5\", \"MRR\"]\n",
        "\n",
        "    return {\n",
        "        \"Total\": {\"value\": total_queries},\n",
        "        **{\n",
        "            m: {\n",
        "                \"value\": sum(v[\"value\"] for v in aggregated_metrics[m]) / len(aggregated_metrics[m]),\n",
        "                \"is_algebraic\": True\n",
        "            } for m in metrics\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "yUdTWpeBAnTm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vllm_config = RFvLLMModelConfig(\n",
        "    model_config={\n",
        "        \"model\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "        \"dtype\": \"half\", # Force half-precision for speed\n",
        "        \"gpu_memory_utilization\": 0.25,\n",
        "        \"enforce_eager\": True,\n",
        "        \"max_model_len\": 2048, # Limits KV cache to prevent OOM\n",
        "        \"disable_log_stats\": True,\n",
        "    },\n",
        "    sampling_params={\n",
        "        \"temperature\": 0.7, # Added for more natural answers\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 128,\n",
        "    },\n",
        "    rag=rag_gpu,\n",
        ")\n",
        "\n",
        "config_set = {\n",
        "    \"vllm_config\": vllm_config,\n",
        "    \"batch_size\": 4,\n",
        "    \"preprocess_fn\": sample_preprocess_fn,\n",
        "    \"postprocess_fn\": sample_postprocess_fn,\n",
        "    \"compute_metrics_fn\": sample_compute_metrics_fn,\n",
        "    \"accumulate_metrics_fn\": sample_accumulate_metrics_fn,\n",
        "    # Matches Code 1's real-time metric aggregation\n",
        "    \"online_strategy_kwargs\": {\n",
        "        \"strategy_name\": \"normal\",\n",
        "        \"confidence_level\": 0.95,\n",
        "        \"use_fpc\": True,\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "zWzlFFquA5TN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_group = RFGridSearch(config_set)\n",
        "experiment = Experiment(experiment_name=\"amazon-electronics-rag-v2\", mode=\"evals\")\n",
        "\n",
        "results = experiment.run_evals(config_group=config_group, dataset=electronics_dataset, num_actors=1,num_shards=4,seed=42)\n",
        "\n",
        "# Cleanup and log viewing\n",
        "experiment.end()\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8851/dispatcher/list-all-pipeline-ids": {
              "data": "W3sicGlwZWxpbmVfaWQiOjQsInNoYXJkc19jb21wbGV0ZWQiOjAsInN0YXR1cyI6ImZhaWxlZCIsInRvdGFsX3NhbXBsZXNfcHJvY2Vzc2VkIjowfSx7InBpcGVsaW5lX2lkIjozLCJzaGFyZHNfY29tcGxldGVkIjowLCJzdGF0dXMiOiJmYWlsZWQiLCJ0b3RhbF9zYW1wbGVzX3Byb2Nlc3NlZCI6MH0seyJwaXBlbGluZV9pZCI6Miwic2hhcmRzX2NvbXBsZXRlZCI6MCwic3RhdHVzIjoiZmFpbGVkIiwidG90YWxfc2FtcGxlc19wcm9jZXNzZWQiOjB9LHsicGlwZWxpbmVfaWQiOjEsInNoYXJkc19jb21wbGV0ZWQiOjEsInN0YXR1cyI6ImZhaWxlZCIsInRvdGFsX3NhbXBsZXNfcHJvY2Vzc2VkIjo1MDB9XQo=",
              "ok": true,
              "headers": [
                [
                  "content-length",
                  "344"
                ],
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:8851/dispatcher/get-pipeline-config-json/4": {
              "data": "eyJjb250ZXh0X2lkIjoyLCJwaXBlbGluZV9jb25maWdfanNvbiI6eyJiYXRjaF9zaXplIjo0LCJtb2RlbF9jb25maWciOnsiZGlzYWJsZV9sb2dfc3RhdHMiOnRydWUsImR0eXBlIjoiaGFsZiIsImVuZm9yY2VfZWFnZXIiOnRydWUsImdwdV9tZW1vcnlfdXRpbGl6YXRpb24iOjAuMjUsIm1heF9tb2RlbF9sZW4iOjIwNDgsIm1vZGVsIjoiUXdlbi9Rd2VuMi41LTAuNUItSW5zdHJ1Y3QifSwib25saW5lX3N0cmF0ZWd5X2t3YXJncyI6eyJjb25maWRlbmNlX2xldmVsIjowLjk1LCJzdHJhdGVneV9uYW1lIjoibm9ybWFsIiwidXNlX2ZwYyI6dHJ1ZX0sInBpcGVsaW5lX3R5cGUiOiJ2bGxtIiwicmFnX2NvbmZpZyI6eyJjaHVua19vdmVybGFwIjozMiwiY2h1bmtfc2l6ZSI6MTI4LCJrIjoyMCwic2VhcmNoX3R5cGUiOiJzaW1pbGFyaXR5IiwidG9wX24iOjEwfSwic2FtcGxpbmdfcGFyYW1zIjp7Im1heF90b2tlbnMiOjEyOCwidGVtcGVyYXR1cmUiOjAuNywidG9wX3AiOjAuOTV9fX0K",
              "ok": true,
              "headers": [
                [
                  "content-length",
                  "501"
                ],
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9TFlxSgGA_zA",
        "outputId": "a37398ad-a810-4b3f-eb02-990352d523e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment amazon-electronics-rag-v2 is currently running. Returning the same experiment object.\n",
            "Any running tasks have been cancelled.\n",
            "ğŸŒ Google Colab detected. Ray dashboard URL: https://8855-gpu-t4-hm-1lpb172kzqkzg-c.asia-southeast1-1.prod.colab.dev\n",
            "ğŸŒ Google Colab detected. Dispatcher URL: https://8851-gpu-t4-hm-1lpb172kzqkzg-c.asia-southeast1-1.prod.colab.dev\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <div id=\"controller_f4b79531\" style=\"font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif; max-width: 900px; margin: 0 auto;\">\n",
              "            <style>\n",
              "                #controller_f4b79531 h3 { margin: 10px 0; font-size: 1.2em; font-weight: 600; }\n",
              "                #controller_f4b79531 .header-info { display: flex; gap: 20px; margin: 10px 0; padding: 10px; background: #f8f9fa; border-radius: 4px; font-size: 13px; }\n",
              "                #controller_f4b79531 .section { margin: 15px 0; }\n",
              "                #controller_f4b79531 .section-label { font-weight: 600; margin-bottom: 8px; font-size: 14px; }\n",
              "                #controller_f4b79531 .button-row { display: flex; gap: 8px; flex-wrap: wrap; margin: 10px 0; }\n",
              "                #controller_f4b79531 select { padding: 6px 12px; border: 1px solid #ccc; border-radius: 4px; font-size: 13px; background: white; min-width: 300px; cursor: pointer; }\n",
              "                #controller_f4b79531 button { padding: 6px 16px; border: none; border-radius: 4px; font-size: 13px; font-weight: 500; cursor: pointer; }\n",
              "                #controller_f4b79531 button:disabled { opacity: 0.5; cursor: not-allowed; }\n",
              "                #controller_f4b79531 .btn-success { background: #28a745; color: white; }\n",
              "                #controller_f4b79531 .btn-danger { background: #dc3545; color: white; }\n",
              "                #controller_f4b79531 .btn-info { background: #17a2b8; color: white; }\n",
              "                #controller_f4b79531 .btn-default { background: #6c757d; color: white; }\n",
              "                #controller_f4b79531 textarea { width: 100%; min-height: 200px; padding: 10px; border: 1px solid #ccc; border-radius: 4px; font-family: 'Courier New', monospace; font-size: 12px; box-sizing: border-box; }\n",
              "                #controller_f4b79531 .status-message { padding: 10px; margin: 10px 0; border-radius: 4px; display: none; }\n",
              "                #controller_f4b79531 .msg-success { background: #d4edda; color: #155724; }\n",
              "                #controller_f4b79531 .msg-error { background: #f8d7da; color: #721c24; }\n",
              "                #controller_f4b79531 .msg-info { background: #d1ecf1; color: #0c5460; }\n",
              "            </style>\n",
              "\n",
              "            <div>\n",
              "                <h3>Interactive Run Controller</h3>\n",
              "                <div class=\"header-info\">\n",
              "                    <div><b>Run ID:</b> <span id=\"pipeline-id-value\">N/A</span></div>\n",
              "                    <div><b>Status:</b> <span id=\"status-value\">Not loaded</span></div>\n",
              "                    <div><b>Last Update:</b> <span id=\"last-update\">Never</span></div>\n",
              "                </div>\n",
              "\n",
              "                <div id=\"status-message\" class=\"status-message\"></div>\n",
              "\n",
              "                <div class=\"section\">\n",
              "                    <div class=\"section-label\">Select a Config ID:</div>\n",
              "                    <select id=\"pipeline-selector\">\n",
              "                        <option value=\"\">Waiting for data...</option>\n",
              "                    </select>\n",
              "                </div>\n",
              "\n",
              "                <div class=\"section\">\n",
              "                    <div class=\"button-row\">\n",
              "                        <button class=\"btn-success\" id=\"resume-btn\">â–¶ Resume</button>\n",
              "                        <button class=\"btn-danger\" id=\"stop-btn\">â–  Stop</button>\n",
              "                        <button class=\"btn-danger\" id=\"delete-btn\">ğŸ—‘ Delete</button>\n",
              "                    </div>\n",
              "                </div>\n",
              "\n",
              "                <div class=\"section\">\n",
              "                    <div class=\"section-label\">Configuration: <span id=\"config-name\">N/A</span></div>\n",
              "                    <textarea id=\"config-text\" readonly>{}</textarea>\n",
              "                    <div class=\"button-row\">\n",
              "                        <button class=\"btn-info\" id=\"clone-btn\">Clone Run</button>\n",
              "                        <button class=\"btn-success\" id=\"submit-clone-btn\" disabled>âœ“ Submit Clone</button>\n",
              "                        <button class=\"btn-danger\" id=\"cancel-clone-btn\" disabled>âœ— Cancel</button>\n",
              "                    </div>\n",
              "                </div>\n",
              "            </div>\n",
              "\n",
              "            <script>\n",
              "                (function() {\n",
              "                    const WIDGET_ID = 'controller_f4b79531';\n",
              "                    const DISPATCHER_URL = 'https://localhost:8851';\n",
              "                    let currentPipelineId = null;\n",
              "                    let currentConfig = null;\n",
              "                    let currentContextId = null;\n",
              "                    let isCloneMode = false;\n",
              "                    let pollingInterval = null;\n",
              "\n",
              "                    // Elements\n",
              "                    const el = {\n",
              "                        pipelineIdValue: document.getElementById('pipeline-id-value'),\n",
              "                        statusValue: document.getElementById('status-value'),\n",
              "                        lastUpdate: document.getElementById('last-update'),\n",
              "                        statusMessage: document.getElementById('status-message'),\n",
              "                        pipelineSelector: document.getElementById('pipeline-selector'),\n",
              "                        resumeBtn: document.getElementById('resume-btn'),\n",
              "                        stopBtn: document.getElementById('stop-btn'),\n",
              "                        deleteBtn: document.getElementById('delete-btn'),\n",
              "                        configName: document.getElementById('config-name'),\n",
              "                        configText: document.getElementById('config-text'),\n",
              "                        cloneBtn: document.getElementById('clone-btn'),\n",
              "                        submitCloneBtn: document.getElementById('submit-clone-btn'),\n",
              "                        cancelCloneBtn: document.getElementById('cancel-clone-btn')\n",
              "                    };\n",
              "\n",
              "                    // Use fetch API with explicit CORS mode and optional auth token\n",
              "                    async function xhrRequest(url, method = 'GET', body = null) {\n",
              "                        const options = {\n",
              "                            method: method,\n",
              "                            headers: {\n",
              "                                'Content-Type': 'application/json'\n",
              "                            },\n",
              "                            mode: 'cors',\n",
              "                            credentials: 'include'  // Include cookies for Colab proxy auth\n",
              "                        };\n",
              "\n",
              "                        if (body) {\n",
              "                            options.body = JSON.stringify(body);\n",
              "                        }\n",
              "\n",
              "                        const response = await fetch(url, options);\n",
              "                        if (!response.ok) {\n",
              "                            throw new Error('HTTP ' + response.status);\n",
              "                        }\n",
              "                        return await response.json();\n",
              "                    }\n",
              "\n",
              "                    async function fetchPipelines() {\n",
              "                        try {\n",
              "                            console.log('Fetching pipelines...');\n",
              "                            const pipelines = await xhrRequest(DISPATCHER_URL + '/dispatcher/list-all-pipeline-ids');\n",
              "                            console.log('Got pipelines:', pipelines.length);\n",
              "\n",
              "                            updatePipelinesDropdown(pipelines);\n",
              "                            el.lastUpdate.textContent = new Date().toLocaleTimeString();\n",
              "\n",
              "                        } catch (error) {\n",
              "                            console.error('Failed to fetch pipelines:', error);\n",
              "                            showMessage('Connection error: ' + error.message, 'error');\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                    async function fetchPipelineConfig(pipelineId) {\n",
              "                        try {\n",
              "                            const data = await xhrRequest(DISPATCHER_URL + `/dispatcher/get-pipeline-config-json/${pipelineId}`);\n",
              "                            const config = data.pipeline_config_json || {};\n",
              "\n",
              "                            currentConfig = config;\n",
              "                            currentContextId = data.context_id;\n",
              "\n",
              "                            el.configName.textContent = config.pipeline_name || 'N/A';\n",
              "\n",
              "                            if (!isCloneMode) {\n",
              "                                el.configText.value = JSON.stringify(config, null, 2);\n",
              "                            }\n",
              "\n",
              "                        } catch (error) {\n",
              "                            console.error('Failed to fetch config:', error);\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                    function updatePipelinesDropdown(pipelines) {\n",
              "                        const selector = el.pipelineSelector;\n",
              "                        const currentSelection = selector.value;\n",
              "\n",
              "                        selector.innerHTML = '';\n",
              "\n",
              "                        if (pipelines && pipelines.length > 0) {\n",
              "                            pipelines.forEach(p => {\n",
              "                                const option = document.createElement('option');\n",
              "                                option.value = p.pipeline_id;\n",
              "                                option.textContent = `Config ID: ${p.pipeline_id} (${p.status || 'unknown'})`;\n",
              "                                selector.appendChild(option);\n",
              "                            });\n",
              "\n",
              "                            if (currentSelection && pipelines.some(p => p.pipeline_id == currentSelection)) {\n",
              "                                selector.value = currentSelection;\n",
              "                                currentPipelineId = currentSelection;\n",
              "                            } else {\n",
              "                                selector.value = pipelines[0].pipeline_id;\n",
              "                                currentPipelineId = pipelines[0].pipeline_id;\n",
              "                                fetchPipelineConfig(currentPipelineId);\n",
              "                            }\n",
              "\n",
              "                            // Update status display\n",
              "                            const currentPipeline = pipelines.find(p => p.pipeline_id == currentPipelineId);\n",
              "                            if (currentPipeline) {\n",
              "                                el.pipelineIdValue.textContent = currentPipeline.pipeline_id;\n",
              "                                el.statusValue.textContent = currentPipeline.status || 'unknown';\n",
              "\n",
              "                                const isCompleted = currentPipeline.status?.toLowerCase() === 'completed';\n",
              "                                el.resumeBtn.disabled = isCompleted;\n",
              "                                el.stopBtn.disabled = isCompleted;\n",
              "                                el.deleteBtn.disabled = isCompleted;\n",
              "                                el.cloneBtn.disabled = isCompleted || !currentContextId;\n",
              "                            }\n",
              "                        } else {\n",
              "                            selector.innerHTML = '<option value=\"\">No pipelines found</option>';\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                    function showMessage(message, type) {\n",
              "                        el.statusMessage.className = 'status-message msg-' + type;\n",
              "                        el.statusMessage.textContent = message;\n",
              "                        el.statusMessage.style.display = 'block';\n",
              "                        setTimeout(() => el.statusMessage.style.display = 'none', 5000);\n",
              "                    }\n",
              "\n",
              "                    async function handleAction(action) {\n",
              "                        if (!currentPipelineId) {\n",
              "                            showMessage('No pipeline selected', 'error');\n",
              "                            return;\n",
              "                        }\n",
              "\n",
              "                        try {\n",
              "                            const endpoint = DISPATCHER_URL + `/dispatcher/${action}-pipeline`;\n",
              "                            const result = await xhrRequest(endpoint, 'POST', { pipeline_id: currentPipelineId });\n",
              "\n",
              "                            showMessage(`âœ“ ${action} completed for pipeline ${currentPipelineId}`, 'success');\n",
              "\n",
              "                            // Refresh after a short delay\n",
              "                            setTimeout(async () => {\n",
              "                                await fetchPipelines();\n",
              "                            }, 500);\n",
              "\n",
              "                        } catch (error) {\n",
              "                            showMessage(`Error: ${error.message}`, 'error');\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                    function enableCloneMode() {\n",
              "                        isCloneMode = true;\n",
              "                        el.configText.readOnly = false;\n",
              "                        el.submitCloneBtn.disabled = false;\n",
              "                        el.cancelCloneBtn.disabled = false;\n",
              "                        el.cloneBtn.disabled = true;\n",
              "                        showMessage('Edit config and click Submit to clone', 'info');\n",
              "                    }\n",
              "\n",
              "                    function disableCloneMode() {\n",
              "                        isCloneMode = false;\n",
              "                        el.configText.readOnly = true;\n",
              "                        el.configText.value = JSON.stringify(currentConfig || {}, null, 2);\n",
              "                        el.submitCloneBtn.disabled = true;\n",
              "                        el.cancelCloneBtn.disabled = true;\n",
              "                        el.cloneBtn.disabled = false;\n",
              "                    }\n",
              "\n",
              "                    async function handleClone() {\n",
              "                        if (!currentPipelineId) {\n",
              "                            showMessage('No pipeline selected', 'error');\n",
              "                            return;\n",
              "                        }\n",
              "\n",
              "                        try {\n",
              "                            // Parse edited config\n",
              "                            let editedConfig;\n",
              "                            try {\n",
              "                                editedConfig = JSON.parse(el.configText.value);\n",
              "                            } catch (e) {\n",
              "                                showMessage('Invalid JSON: ' + e.message, 'error');\n",
              "                                return;\n",
              "                            }\n",
              "\n",
              "                            // Validate required fields\n",
              "                            if (!editedConfig.pipeline_type) {\n",
              "                                showMessage('config_json must include pipeline_type', 'error');\n",
              "                                return;\n",
              "                            }\n",
              "\n",
              "                            // Send clone request\n",
              "                            const cloneRequest = {\n",
              "                                parent_pipeline_id: currentPipelineId,\n",
              "                                config_json: editedConfig\n",
              "                            };\n",
              "\n",
              "                            const result = await xhrRequest(\n",
              "                                DISPATCHER_URL + '/dispatcher/clone-pipeline',\n",
              "                                'POST',\n",
              "                                cloneRequest\n",
              "                            );\n",
              "\n",
              "                            showMessage(`âœ“ Cloned from Config ID ${currentPipelineId} successfully!`, 'success');\n",
              "                            disableCloneMode();\n",
              "\n",
              "                            // Refresh after delay\n",
              "                            setTimeout(async () => {\n",
              "                                await fetchPipelines();\n",
              "                            }, 1000);\n",
              "\n",
              "                        } catch (error) {\n",
              "                            showMessage(`Error cloning: ${error.message}`, 'error');\n",
              "                        }\n",
              "                    }\n",
              "\n",
              "                    // Event listeners\n",
              "                    el.pipelineSelector.addEventListener('change', (e) => {\n",
              "                        if (e.target.value) {\n",
              "                            currentPipelineId = parseInt(e.target.value);\n",
              "                            fetchPipelineConfig(currentPipelineId);\n",
              "                        }\n",
              "                    });\n",
              "\n",
              "                    el.resumeBtn.addEventListener('click', () => handleAction('resume'));\n",
              "                    el.stopBtn.addEventListener('click', () => handleAction('stop'));\n",
              "                    el.deleteBtn.addEventListener('click', () => handleAction('delete'));\n",
              "\n",
              "                    el.cloneBtn.addEventListener('click', enableCloneMode);\n",
              "                    el.submitCloneBtn.addEventListener('click', handleClone);\n",
              "                    el.cancelCloneBtn.addEventListener('click', () => {\n",
              "                        disableCloneMode();\n",
              "                        showMessage('Cancelled clone', 'info');\n",
              "                    });\n",
              "\n",
              "                    // Initial fetch\n",
              "                    console.log('UI initialized, fetching initial data...');\n",
              "                    setTimeout(async () => {\n",
              "                        await fetchPipelines();\n",
              "\n",
              "                        // Start polling - use HTTP fetch (works even when kernel is busy)\n",
              "                        pollingInterval = setInterval(async () => {\n",
              "                            await fetchPipelines();\n",
              "                        }, 3000.0);\n",
              "                        console.log('Polling started: every 3.0s');\n",
              "                    }, 1000);\n",
              "\n",
              "                    // Cleanup on unload\n",
              "                    window.addEventListener('beforeunload', () => {\n",
              "                        if (pollingInterval) clearInterval(pollingInterval);\n",
              "                    });\n",
              "                })();\n",
              "            </script>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Preprocessing RAG Sources ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ae660166c60>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_3b613\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_3b613_level0_col0\" class=\"col_heading level0 col0\" >RAG Source ID</th>\n",
              "      <th id=\"T_3b613_level0_col1\" class=\"col_heading level0 col1\" >Status</th>\n",
              "      <th id=\"T_3b613_level0_col2\" class=\"col_heading level0 col2\" >Duration</th>\n",
              "      <th id=\"T_3b613_level0_col3\" class=\"col_heading level0 col3\" >Details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_3b613_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_3b613_row0_col1\" class=\"data row0 col1\" >Building</td>\n",
              "      <td id=\"T_3b613_row0_col2\" class=\"data row0 col2\" >0.0s</td>\n",
              "      <td id=\"T_3b613_row0_col3\" class=\"data row0 col3\" >FAISS, GPU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_3b613_row1_col0\" class=\"data row1 col0\" >2</td>\n",
              "      <td id=\"T_3b613_row1_col1\" class=\"data row1 col1\" >Building</td>\n",
              "      <td id=\"T_3b613_row1_col2\" class=\"data row1 col2\" >0.0s</td>\n",
              "      <td id=\"T_3b613_row1_col3\" class=\"data row1 col3\" >FAISS, GPU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2324814319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"amazon-electronics-rag-v2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"evals\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melectronics_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Cleanup and log viewing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rapidfireai/experiment.py\u001b[0m in \u001b[0;36mrun_evals\u001b[0;34m(self, config_group, dataset, num_shards, seed, num_actors, gpus_per_actor, cpus_per_actor)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# Delegate all complexity to Controller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             results = self.controller.run_multi_pipeline_inference(\n\u001b[0m\u001b[1;32m    403\u001b[0m                 \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mconfig_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_group\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rapidfireai/evals/scheduling/controller.py\u001b[0m in \u001b[0;36mrun_multi_pipeline_inference\u001b[0;34m(self, experiment_id, config_group, dataset, num_shards, seed, num_actors, num_gpus, num_cpus)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;31m# PHASE 3: Setup context generators (collect unique, check DB, build if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_context_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_leaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# PHASE 4: Create query processing actors (shared pool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rapidfireai/evals/scheduling/controller.py\u001b[0m in \u001b[0;36m_setup_context_generators\u001b[0;34m(self, config_leaves, db)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Building {len(contexts_to_build)} context(s) in parallel...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_rag_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontexts_to_build\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to build contexts in parallel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rapidfireai/evals/scheduling/controller.py\u001b[0m in \u001b[0;36mbuild_rag_components\u001b[0;34m(self, contexts_to_build, db)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;31m# Wait for this specific build to complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"future\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout, _tensor_transport)\u001b[0m\n\u001b[1;32m   2965\u001b[0m             )\n\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2967\u001b[0;31m         values, debugger_breakpoint = worker.get_objects(\n\u001b[0m\u001b[1;32m   2968\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tensor_transport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_tensor_transport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_refs, timeout, return_exceptions, skip_deserialization, _tensor_transport)\u001b[0m\n\u001b[1;32m    974\u001b[0m         serialized_objects: List[\n\u001b[1;32m    975\u001b[0m             \u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializedRayObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/includes/common.pxi\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([{k: (v['value'] if isinstance(v, dict) else v) for k, v in {**m, 'run_id': rid}.items()} for rid, (_, m) in results.items()])"
      ],
      "metadata": {
        "id": "80zku7BACCf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08AEXyCgkbkV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}